{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define best node as the node whose metrics give the highest accuracy\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/home/ishwar/Documents/epilepsy-detection-main/network_metrics_timeseries/theta_A_W_uni11_100ms_054.mat_network_metrics_timeseries.npy\"\n",
    "\n",
    "data = np.load(file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clustering_coefficient': array([0.        , 0.        , 0.        , 1.        , 0.66666667,\n",
       "        1.        , 1.        , 0.        , 0.66666667, 0.5       ]),\n",
       " 'degree_centrality': array([0.        , 0.        , 0.        , 0.33333333, 0.44444444,\n",
       "        0.22222222, 0.33333333, 0.        , 0.33333333, 0.55555556]),\n",
       " 'betweenness_centrality': array([0.        , 0.        , 0.        , 0.        , 0.02777778,\n",
       "        0.        , 0.        , 0.        , 0.01388889, 0.09722222]),\n",
       " 'closeness_centrality': array([0.        , 0.        , 0.        , 0.3968254 , 0.46296296,\n",
       "        0.34722222, 0.3968254 , 0.        , 0.3968254 , 0.55555556]),\n",
       " 'eigenvector_centrality': array([2.69123483e-10, 2.69123483e-10, 2.69123483e-10, 3.94581016e-01,\n",
       "        4.72532825e-01, 2.49254723e-01, 3.94581016e-01, 2.69123483e-10,\n",
       "        3.53464875e-01, 5.27502642e-01]),\n",
       " 'pagerank': array([0.02272746, 0.02272746, 0.02272746, 0.13629869, 0.17699465,\n",
       "        0.09975902, 0.13629869, 0.02272746, 0.14007832, 0.21966079]),\n",
       " 'katz_centrality': array([0.23613269, 0.23613269, 0.23613269, 0.35038253, 0.38188481,\n",
       "        0.31180831, 0.35038253, 0.23613269, 0.34652511, 0.41023102]),\n",
       " 'degree_distribution': array([0, 0, 0, 3, 4, 2, 3, 0, 3, 5]),\n",
       " 'assortativity_coefficient': array([-0.38297872]),\n",
       " 'reciprocity': array([0.]),\n",
       " 'communities': [frozenset({3, 4, 6}),\n",
       "  frozenset({5, 8, 9}),\n",
       "  frozenset({0}),\n",
       "  frozenset({1}),\n",
       "  frozenset({2}),\n",
       "  frozenset({7})],\n",
       " 'degree_centralities': array([0.        , 0.        , 0.        , 0.33333333, 0.44444444,\n",
       "        0.22222222, 0.33333333, 0.        , 0.33333333, 0.55555556]),\n",
       " 'betweenness_centralities': array([0.        , 0.        , 0.        , 0.        , 0.02777778,\n",
       "        0.        , 0.        , 0.        , 0.01388889, 0.09722222]),\n",
       " 'closeness_centralities': array([0.        , 0.        , 0.        , 0.3968254 , 0.46296296,\n",
       "        0.34722222, 0.3968254 , 0.        , 0.3968254 , 0.55555556]),\n",
       " 'eigenvector_centralities': array([2.69123483e-10, 2.69123483e-10, 2.69123483e-10, 3.94581016e-01,\n",
       "        4.72532825e-01, 2.49254723e-01, 3.94581016e-01, 2.69123483e-10,\n",
       "        3.53464875e-01, 5.27502642e-01])}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from a csv\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    data = []\n",
    "    with open(filename , 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_data(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_data_from_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    #Create input, labels pairs where input is all columns except the first and output is 0 for first and last 5000 rows and 1 for the rest\n",
    "    X = df.iloc[:,1:]\n",
    "    y = [0]*5000 + [1]*(df.shape[0]-10000) + [0]*5000\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uni_167_Tomic-Stoja_RMT_no-ref-ch.csv\n",
      "uni_081_Schlick-Reinhard_LMT_no-ref-ch_no-G,F,I-channels.csv\n",
      "uni_113_Ahmed-Nasteha-Mohamud_RMT_no-ref-ch.csv\n",
      "uni_112_Ahmed-Nasteha-Mohamud_LMT_no-ref-ch.csv\n",
      "uni_080_Schlick-Reinhard_LMT_no-ref-ch_no-G,F,I-channels.csv\n",
      "uni_054_Heide-Astrid_LMT_no-ref-ch_no-G,F,I-channels.csv\n",
      "uni_117_Senzek-Heiko_RMT_no-ref-ch_no-G,F,I-channels.csv\n",
      "uni_125_Erbst-Doris_LMT_no-ref-ch_no-G,F,I-channels.csv\n",
      "uni_111_Ahmed-Nasteha-Mohamud_LMT_no-ref-ch.csv\n",
      "uni_140_Pott-Eberhand_RMT_no-ref-ch.csv\n"
     ]
    }
   ],
   "source": [
    "# build data for all files in dataset folder and append to X_all and y_all. Note X_all has to be a dataframe\n",
    "\n",
    "X_all = pd.DataFrame()\n",
    "y_all = []\n",
    "for file in os.listdir('../csv dataset/part 1(10 eps)-unfiltered,no ref ch, no G,F,I ch'):\n",
    "    print(file)\n",
    "    if file.endswith('.csv'):\n",
    "        X, y = build_data_from_csv('../csv dataset/part 1(10 eps)-unfiltered,no ref ch, no G,F,I ch/' + file)\n",
    "        X_all = pd.concat([X_all, X])\n",
    "        y_all += y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_saved = X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442864, 10)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.array(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442864, 10)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all shape  (442860, 10)\n"
     ]
    }
   ],
   "source": [
    "# drop last few rows to make it divisible by 20\n",
    "rows_dropped = X_all.shape[0]%20 \n",
    "X_all = X_all[:-rows_dropped]\n",
    "print(\"X_all shape \",X_all.shape)\n",
    "\n",
    "X_all = X_all.reshape(-1, 20, X_all.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22143, 20, 10)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22139, 20, 10)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop last 4 rows\n",
    "X_all = X_all[:-4,:,:]\n",
    "\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(X, feature):\n",
    "    X_all = np.concatenate((X, feature), axis=1)\n",
    "\n",
    "    return X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22139, 1)\n"
     ]
    }
   ],
   "source": [
    "def clustering_coeffiecient_features(node):\n",
    "    network_metrics_dir = \"/home/ishwar/Documents/epilepsy-detection-main/network_metrics_timeseries/\"\n",
    "    files = os.listdir(network_metrics_dir)\n",
    "    features = []\n",
    "    for file in files:\n",
    "        if file.endswith('.npy'):\n",
    "            data = np.load(network_metrics_dir + file, allow_pickle=True)\n",
    "            for i in range(len(data)):\n",
    "                features.append(data[i][\"clustering_coefficient\"][node])\n",
    "            \n",
    "    features = np.array(features)\n",
    "    features = features.reshape(-1, 1)\n",
    "    print(features.shape)\n",
    "    return features\n",
    "        # break\n",
    "\n",
    "\n",
    "clustering_coeffiecient_features = clustering_coeffiecient_features(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 22139 x 10 to 22139 x 1 x 10\n",
    "clustering_coeffiecient_features = clustering_coeffiecient_features.reshape(-1, 1, clustering_coeffiecient_features.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_all = add_features(X_all, clustering_coeffiecient_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22139, 20, 10)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442864"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the chunking for y_all as well\n",
    "y_all_new = []\n",
    "for i in range(0, len(y_all), 20):\n",
    "    y_all_new.append(y_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22144"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_all_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22139"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = y_all_new[:-5]\n",
    "\n",
    "len(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22139, 200)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.12      0.21       993\n",
      "           1       0.80      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.74      0.55      0.54      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 122  871]\n",
      " [  54 3381]]\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier on X_all and y_all\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# classification report, confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_all_flat= X_all.reshape(X_all.shape[0], -1)\n",
    "print(X_all_flat.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all_flat, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22139, 200)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.12      0.19       993\n",
      "           1       0.79      0.97      0.87      3435\n",
      "\n",
      "    accuracy                           0.78      4428\n",
      "   macro avg       0.65      0.54      0.53      4428\n",
      "weighted avg       0.73      0.78      0.72      4428\n",
      "\n",
      "[[ 116  877]\n",
      " [ 109 3326]]\n"
     ]
    }
   ],
   "source": [
    "# knn on X_all and y_all\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNearestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# classification report, confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_all_flat= X_all.reshape(X_all.shape[0], -1)\n",
    "print(X_all_flat.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all_flat, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = KNearestClassifier(n_neighbors=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_coeffiecient_features(node):\n",
    "    network_metrics_dir = \"/home/ishwar/Documents/epilepsy-detection-main/network_metrics_timeseries/\"\n",
    "    files = os.listdir(network_metrics_dir)\n",
    "    features = []\n",
    "    for file in files:\n",
    "        if file.endswith('.npy'):\n",
    "            data = np.load(network_metrics_dir + file, allow_pickle=True)\n",
    "            for i in range(len(data)):\n",
    "                features.append(data[i][\"clustering_coefficient\"][node])\n",
    "            \n",
    "    features = np.array(features)\n",
    "    features = features.reshape(-1, 1)\n",
    "    print(features.shape)\n",
    "    return features\n",
    "        # break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22139, 200)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22139, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22139, 1)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_coeffiecient_features(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.12      0.21       993\n",
      "           1       0.79      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.75      0.55      0.54      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 120  873]\n",
      " [  52 3383]]\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier on X_all and y_all\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# classification report, confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_all_flat= X_all.reshape(X_all.shape[0], -1)\n",
    "X_all_flat= add_features(X_all_flat, clustering_coeffiecient_features(1))\n",
    "\n",
    "print(X_all_flat.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all_flat, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.13      0.22       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.76      0.56      0.55      4428\n",
      "weighted avg       0.78      0.79      0.73      4428\n",
      "\n",
      "[[ 131  862]\n",
      " [  49 3386]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.12      0.21       993\n",
      "           1       0.79      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.75      0.55      0.54      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 120  873]\n",
      " [  52 3383]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.12      0.21       993\n",
      "           1       0.79      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.74      0.55      0.54      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 120  873]\n",
      " [  55 3380]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.13      0.21       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.76      0.56      0.55      4428\n",
      "weighted avg       0.78      0.79      0.73      4428\n",
      "\n",
      "[[ 125  868]\n",
      " [  50 3385]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.12      0.20       993\n",
      "           1       0.79      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.76      0.55      0.54      4428\n",
      "weighted avg       0.78      0.79      0.73      4428\n",
      "\n",
      "[[ 118  875]\n",
      " [  45 3390]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.11      0.19       993\n",
      "           1       0.79      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.74      0.55      0.54      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 113  880]\n",
      " [  54 3381]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.13      0.21       993\n",
      "           1       0.80      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.73      0.55      0.54      4428\n",
      "weighted avg       0.76      0.79      0.73      4428\n",
      "\n",
      "[[ 125  868]\n",
      " [  65 3370]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.13      0.23       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.80      4428\n",
      "   macro avg       0.77      0.56      0.55      4428\n",
      "weighted avg       0.79      0.80      0.73      4428\n",
      "\n",
      "[[ 132  861]\n",
      " [  45 3390]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.13      0.22       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.80      4428\n",
      "   macro avg       0.77      0.56      0.55      4428\n",
      "weighted avg       0.79      0.80      0.73      4428\n",
      "\n",
      "[[ 130  863]\n",
      " [  44 3391]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.12      0.21       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.75      0.55      0.55      4428\n",
      "weighted avg       0.78      0.79      0.73      4428\n",
      "\n",
      "[[ 123  870]\n",
      " [  51 3384]]\n",
      "Best node is  7  with accuracy  0.7953929539295393\n"
     ]
    }
   ],
   "source": [
    "# Best node is one that gives the highest accuracy\n",
    "# Define a function that takes in a node and returns the accuracy\n",
    "\n",
    "def get_accuracy(node):\n",
    "    X_all_flat= X_all.reshape(X_all.shape[0], -1)\n",
    "    X_all_flat= add_features(X_all_flat, clustering_coeffiecient_features(node))\n",
    "\n",
    "    print(X_all_flat.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all_flat, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "best_node = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "for i in range(10):\n",
    "    accuracy = get_accuracy(i)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_node = i\n",
    "\n",
    "print(\"Best node is \", best_node, \" with accuracy \", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22139, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22139, 1)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def degree_distribution_features(node):\n",
    "    network_metrics_dir = \"/home/ishwar/Documents/epilepsy-detection-main/network_metrics_timeseries/\"\n",
    "    files = os.listdir(network_metrics_dir)\n",
    "    features = []\n",
    "    for file in files:\n",
    "        if file.endswith('.npy'):\n",
    "            data = np.load(network_metrics_dir + file, allow_pickle=True)\n",
    "            for i in range(len(data)):\n",
    "                features.append(data[i][\"degree_distribution\"][node])\n",
    "            \n",
    "    features = np.array(features)\n",
    "    features = features.reshape(-1, 1)\n",
    "    print(features.shape)\n",
    "    return features\n",
    "        # break\n",
    "\n",
    "degree_distribution_features(1).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.14      0.23       993\n",
      "           1       0.80      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.76      0.56      0.56      4428\n",
      "weighted avg       0.78      0.79      0.74      4428\n",
      "\n",
      "[[ 137  856]\n",
      " [  53 3382]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.12      0.21       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.76      0.55      0.54      4428\n",
      "weighted avg       0.78      0.79      0.73      4428\n",
      "\n",
      "[[ 120  873]\n",
      " [  46 3389]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.12      0.21       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.76      0.55      0.54      4428\n",
      "weighted avg       0.78      0.79      0.73      4428\n",
      "\n",
      "[[ 121  872]\n",
      " [  47 3388]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.12      0.21       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.78      0.56      0.55      4428\n",
      "weighted avg       0.79      0.79      0.73      4428\n",
      "\n",
      "[[ 122  871]\n",
      " [  38 3397]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.12      0.20       993\n",
      "           1       0.79      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.74      0.55      0.54      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 117  876]\n",
      " [  53 3382]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.12      0.20       993\n",
      "           1       0.79      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.74      0.55      0.54      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 116  877]\n",
      " [  55 3380]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.13      0.22       993\n",
      "           1       0.80      0.98      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.74      0.56      0.55      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 131  862]\n",
      " [  58 3377]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.13      0.22       993\n",
      "           1       0.80      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.77      0.56      0.55      4428\n",
      "weighted avg       0.79      0.79      0.73      4428\n",
      "\n",
      "[[ 126  867]\n",
      " [  43 3392]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.12      0.20       993\n",
      "           1       0.79      0.99      0.88      3435\n",
      "\n",
      "    accuracy                           0.79      4428\n",
      "   macro avg       0.75      0.55      0.54      4428\n",
      "weighted avg       0.77      0.79      0.73      4428\n",
      "\n",
      "[[ 115  878]\n",
      " [  48 3387]]\n",
      "(22139, 1)\n",
      "(22139, 201)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [187], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mget_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accuracy \u001b[38;5;241m>\u001b[39m best_accuracy:\n\u001b[1;32m     31\u001b[0m         best_accuracy \u001b[38;5;241m=\u001b[39m accuracy\n",
      "Cell \u001b[0;32mIn [187], line 14\u001b[0m, in \u001b[0;36mget_accuracy\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_all_flat, y_all, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# accuracy_score(y_test, y_pred)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Best node is one that gives the highest accuracy\n",
    "# Define a function that takes in a node and returns the accuracy\n",
    "\n",
    "def get_accuracy(node):\n",
    "    X_all_flat= X_all.reshape(X_all.shape[0], -1)\n",
    "    X_all_flat= add_features(X_all_flat, degree_distribution_features(node))\n",
    "\n",
    "    print(X_all_flat.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all_flat, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "best_node = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "for i in range(10):\n",
    "    accuracy = get_accuracy(i)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_node = i\n",
    "\n",
    "print(\"Best node is \", best_node, \" with accuracy \", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a  simple neural network that takes samples of size 20 and outputs 1\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class EpilepsyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "class EpilepsyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EpilepsyNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(20*10, 100)\n",
    "        # self.combine = nn.Linear(101, 1)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        # y = torch.tensor(y).double()\n",
    "        x = x.view(-1, 20*10)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # x = self.combine(torch.cat((x, y)))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22139, 20, 10)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset and dataloader\n",
    "\n",
    "dataset = EpilepsyDataset(X_all, y_all)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# splits the data into train and test\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, extra):\n",
    "    size = dataloader.__len__\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "\n",
    "        # print types of X and extra\n",
    "        # print(X.type())\n",
    "\n",
    "        pred = model(X)\n",
    "        #print(\"pred: \", pred, \"y: \", y)\n",
    "        y = y.float()\n",
    "        y = y.view(-1, 1)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        #print(f\"loss: {loss:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, extra):\n",
    "    size = len(dataloader)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            y = y.float()\n",
    "            y = y.view(-1, 1)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            out = pred\n",
    "            if(y[0] == 1):\n",
    "              if(out[0] >= out[1]):\n",
    "                tp += 1\n",
    "              elif(out[0] < out[1]):\n",
    "                #print(out)\n",
    "                fn += 1\n",
    "            elif(y[0] == 0):\n",
    "              if(out[0] >= out[1]):\n",
    "                fp += 1\n",
    "              elif(out[0] < out[1]):\n",
    "                tn += 1\n",
    "    #print(test_loss, num_batches)\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    #print(f\"Test Error: \\n Metrics: {[tp, fp, tn, fn]}, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return [tp, fp, tn, fn], test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EpilepsyNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "acc:  0.5035971223021583 pre:  0.8135593220338984 rec:  0.4528301886792453 spe:  0.6666666666666666 f_score:  0.5818181818181819 c:  [48, 11, 22, 58] loss : 0.46927581127170176\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "acc:  0.60431654676259 pre:  0.8656716417910447 rec:  0.5576923076923077 spe:  0.7428571428571429 f_score:  0.6783625730994152 c:  [58, 9, 26, 46] loss : 0.46214580589489973\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "acc:  0.5827338129496403 pre:  0.84375 rec:  0.5294117647058824 spe:  0.7297297297297297 f_score:  0.6506024096385543 c:  [54, 10, 27, 48] loss : 0.4598257125710412\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "acc:  0.6474820143884892 pre:  0.88 rec:  0.6226415094339622 spe:  0.7272727272727273 f_score:  0.729281767955801 c:  [66, 9, 24, 40] loss : 0.45818712160312874\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "acc:  0.5899280575539568 pre:  0.8888888888888888 rec:  0.5663716814159292 spe:  0.6923076923076923 f_score:  0.6918918918918918 c:  [64, 8, 18, 49] loss : 0.45675215028601585\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "acc:  0.6187050359712231 pre:  0.8695652173913043 rec:  0.5769230769230769 spe:  0.7428571428571429 f_score:  0.6936416184971097 c:  [60, 9, 26, 44] loss : 0.4550575340608899\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "acc:  0.60431654676259 pre:  0.88 rec:  0.5892857142857143 spe:  0.6666666666666666 f_score:  0.7058823529411765 c:  [66, 9, 18, 46] loss : 0.456437206203989\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "acc:  0.6115107913669064 pre:  0.9102564102564102 rec:  0.6016949152542372 spe:  0.6666666666666666 f_score:  0.7244897959183673 c:  [71, 7, 14, 47] loss : 0.45655580068663726\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "acc:  0.6474820143884892 pre:  0.88 rec:  0.6226415094339622 spe:  0.7272727272727273 f_score:  0.729281767955801 c:  [66, 9, 24, 40] loss : 0.4558338999962635\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "acc:  0.5251798561151079 pre:  0.8032786885245902 rec:  0.47572815533980584 spe:  0.6666666666666666 f_score:  0.5975609756097562 c:  [49, 12, 24, 54] loss : 0.4560413955570125\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "acc:  0.5971223021582733 pre:  0.8695652173913043 rec:  0.5607476635514018 spe:  0.71875 f_score:  0.6818181818181818 c:  [60, 9, 23, 47] loss : 0.4552895536096834\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "acc:  0.6330935251798561 pre:  0.84 rec:  0.6176470588235294 spe:  0.6756756756756757 f_score:  0.711864406779661 c:  [63, 12, 25, 39] loss : 0.45803992471677796\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "acc:  0.6187050359712231 pre:  0.8695652173913043 rec:  0.5769230769230769 spe:  0.7428571428571429 f_score:  0.6936416184971097 c:  [60, 9, 26, 44] loss : 0.45442153245425054\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "acc:  0.6258992805755396 pre:  0.8888888888888888 rec:  0.5925925925925926 spe:  0.7419354838709677 f_score:  0.711111111111111 c:  [64, 8, 23, 44] loss : 0.45600248315780284\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "acc:  0.5899280575539568 pre:  0.8552631578947368 rec:  0.5855855855855856 spe:  0.6071428571428571 f_score:  0.6951871657754011 c:  [65, 11, 17, 46] loss : 0.4556654176051668\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "acc:  0.6187050359712231 pre:  0.8356164383561644 rec:  0.5980392156862745 spe:  0.6756756756756757 f_score:  0.6971428571428572 c:  [61, 12, 25, 41] loss : 0.45558577604431044\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "acc:  0.5827338129496403 pre:  0.9076923076923077 rec:  0.5315315315315315 spe:  0.7857142857142857 f_score:  0.6704545454545454 c:  [59, 6, 22, 52] loss : 0.4551047462996819\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "acc:  0.6546762589928058 pre:  0.9552238805970149 rec:  0.5871559633027523 spe:  0.9 f_score:  0.7272727272727273 c:  [64, 3, 27, 45] loss : 0.45506452527835217\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "acc:  0.6258992805755396 pre:  0.8648648648648649 rec:  0.6037735849056604 spe:  0.696969696969697 f_score:  0.7111111111111112 c:  [64, 10, 23, 42] loss : 0.4555643218026744\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "acc:  0.60431654676259 pre:  0.8767123287671232 rec:  0.5818181818181818 spe:  0.6896551724137931 f_score:  0.6994535519125683 c:  [64, 9, 20, 46] loss : 0.45547317139965166\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "acc:  0.5827338129496403 pre:  0.8732394366197183 rec:  0.5585585585585585 spe:  0.6785714285714286 f_score:  0.6813186813186813 c:  [62, 9, 19, 49] loss : 0.45469789689393353\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "acc:  0.5611510791366906 pre:  0.7702702702702703 rec:  0.5643564356435643 spe:  0.5526315789473685 f_score:  0.6514285714285714 c:  [57, 17, 21, 44] loss : 0.4552640560076391\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "acc:  0.6115107913669064 pre:  0.8271604938271605 rec:  0.6261682242990654 spe:  0.5625 f_score:  0.7127659574468085 c:  [67, 14, 18, 40] loss : 0.4559966935742673\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "acc:  0.6546762589928058 pre:  0.8395061728395061 rec:  0.6601941747572816 spe:  0.6388888888888888 f_score:  0.7391304347826088 c:  [68, 13, 23, 35] loss : 0.4547845716956708\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "acc:  0.5755395683453237 pre:  0.8484848484848485 rec:  0.5333333333333333 spe:  0.7058823529411765 f_score:  0.6549707602339182 c:  [56, 10, 24, 49] loss : 0.4553606119944895\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "acc:  0.6115107913669064 pre:  0.9130434782608695 rec:  0.5675675675675675 spe:  0.7857142857142857 f_score:  0.6999999999999998 c:  [63, 6, 22, 48] loss : 0.45589319182385646\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "acc:  0.5467625899280576 pre:  0.84375 rec:  0.5046728971962616 spe:  0.6875 f_score:  0.6315789473684211 c:  [54, 10, 22, 53] loss : 0.4564809854939687\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "acc:  0.5899280575539568 pre:  0.9333333333333333 rec:  0.5137614678899083 spe:  0.8666666666666667 f_score:  0.6627218934911242 c:  [56, 4, 26, 53] loss : 0.4587329372013216\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "acc:  0.6258992805755396 pre:  0.8108108108108109 rec:  0.6122448979591837 spe:  0.6585365853658537 f_score:  0.6976744186046512 c:  [60, 14, 27, 38] loss : 0.4562975113554824\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "acc:  0.5683453237410072 pre:  0.7971014492753623 rec:  0.5445544554455446 spe:  0.631578947368421 f_score:  0.6470588235294118 c:  [55, 14, 24, 46] loss : 0.456430842121728\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "acc:  0.6187050359712231 pre:  0.8571428571428571 rec:  0.5510204081632653 spe:  0.7804878048780488 f_score:  0.670807453416149 c:  [54, 9, 32, 44] loss : 0.45758036014845044\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "acc:  0.5827338129496403 pre:  0.8923076923076924 rec:  0.5321100917431193 spe:  0.7666666666666667 f_score:  0.6666666666666666 c:  [58, 7, 23, 51] loss : 0.45644001362563896\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "acc:  0.60431654676259 pre:  0.8354430379746836 rec:  0.6111111111111112 spe:  0.5806451612903226 f_score:  0.7058823529411765 c:  [66, 13, 18, 42] loss : 0.4566732943058014\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "acc:  0.5611510791366906 pre:  0.8666666666666667 rec:  0.49523809523809526 spe:  0.7647058823529411 f_score:  0.6303030303030304 c:  [52, 8, 26, 53] loss : 0.456450838193619\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "acc:  0.5611510791366906 pre:  0.873015873015873 rec:  0.5092592592592593 spe:  0.7419354838709677 f_score:  0.6432748538011696 c:  [55, 8, 23, 53] loss : 0.45692607224416387\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "acc:  0.5971223021582733 pre:  0.855072463768116 rec:  0.5619047619047619 spe:  0.7058823529411765 f_score:  0.67816091954023 c:  [59, 10, 24, 46] loss : 0.4576948025672556\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "acc:  0.6762589928057554 pre:  0.9125 rec:  0.6576576576576577 spe:  0.75 f_score:  0.7643979057591623 c:  [73, 7, 21, 38] loss : 0.4579012772376589\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "acc:  0.5899280575539568 pre:  0.875 rec:  0.5675675675675675 spe:  0.6785714285714286 f_score:  0.6885245901639344 c:  [63, 9, 19, 48] loss : 0.4579118124658255\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "acc:  0.6402877697841727 pre:  0.9230769230769231 rec:  0.6206896551724138 spe:  0.7391304347826086 f_score:  0.7422680412371133 c:  [72, 6, 17, 44] loss : 0.45678083711176465\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "acc:  0.6258992805755396 pre:  0.9342105263157895 rec:  0.6016949152542372 spe:  0.7619047619047619 f_score:  0.7319587628865979 c:  [71, 5, 16, 47] loss : 0.45725681209306923\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "acc:  0.6402877697841727 pre:  0.9365079365079365 rec:  0.5619047619047619 spe:  0.8823529411764706 f_score:  0.7023809523809524 c:  [59, 4, 30, 46] loss : 0.4567367639258611\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "acc:  0.6187050359712231 pre:  0.8769230769230769 rec:  0.5588235294117647 spe:  0.7837837837837838 f_score:  0.6826347305389222 c:  [57, 8, 29, 45] loss : 0.45905384807277927\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "acc:  0.5899280575539568 pre:  0.8548387096774194 rec:  0.5247524752475248 spe:  0.7631578947368421 f_score:  0.6503067484662577 c:  [53, 9, 29, 48] loss : 0.4581262248454334\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "acc:  0.5683453237410072 pre:  0.8421052631578947 rec:  0.48484848484848486 spe:  0.775 f_score:  0.6153846153846154 c:  [48, 9, 31, 51] loss : 0.4591897495573373\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "acc:  0.5251798561151079 pre:  0.8153846153846154 rec:  0.4953271028037383 spe:  0.625 f_score:  0.6162790697674418 c:  [53, 12, 20, 54] loss : 0.4580996249862712\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "acc:  0.6546762589928058 pre:  0.8648648648648649 rec:  0.6274509803921569 spe:  0.7297297297297297 f_score:  0.7272727272727273 c:  [64, 10, 27, 38] loss : 0.4591405891257224\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "acc:  0.60431654676259 pre:  0.9076923076923077 rec:  0.5462962962962963 spe:  0.8064516129032258 f_score:  0.6820809248554914 c:  [59, 6, 25, 49] loss : 0.4579879049774554\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "acc:  0.6330935251798561 pre:  0.8933333333333333 rec:  0.6090909090909091 spe:  0.7241379310344828 f_score:  0.7243243243243244 c:  [67, 8, 21, 43] loss : 0.4579639731765651\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "acc:  0.6115107913669064 pre:  0.84375 rec:  0.5510204081632653 spe:  0.7560975609756098 f_score:  0.6666666666666666 c:  [54, 10, 31, 44] loss : 0.4589619083370236\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "acc:  0.5899280575539568 pre:  0.8450704225352113 rec:  0.5660377358490566 spe:  0.6666666666666666 f_score:  0.6779661016949151 c:  [60, 11, 22, 46] loss : 0.459351857467521\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [20], gamma=0.001)\n",
    "\n",
    "epochs = 50\n",
    "max_c = -1\n",
    "max_c_epoch = -1\n",
    "min_tl = 9999\n",
    "min_tl_epoch = 9999\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer, 1)\n",
    "    #test(train_dataloader, model, loss_fn)\n",
    "    c, tl = test(test_loader, model, loss_fn, 1)\n",
    "    acc = (c[0] + c[2])/np.sum(c)\n",
    "    pre = c[0]/(c[0]+c[1])\n",
    "    sen = c[0]/(c[0]+c[3])\n",
    "    spe = c[2]/(c[1]+c[2])\n",
    "    f_score = 2*(pre*sen)/(pre+sen)\n",
    "    print(\"acc: \", acc, \"pre: \", pre, \"rec: \", sen, \"spe: \", spe, \"f_score: \", f_score, \"c: \", c, \"loss :\" , tl)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
